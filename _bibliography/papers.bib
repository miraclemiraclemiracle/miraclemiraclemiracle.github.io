---
---

@string{EJOR = {European Journal of Operational Research}}
@string{YAC = {Youth Academic Annual Conference of Chinese Association of Automation}}


@article{liu2025coherency,
  bibtex_show={false},
  title={Coherency Analysis in Nonlinear Heterogeneous Power Networks: A Blended Dynamics Approach},
  author={Yixuan Liu and Yingzhu Liu and Pengcheng You},
  year={2025},
  selected={true},
  journal = {Under Review},
  preview={homepage_pub_coherency.png}
}

@article{WANG2025,
abbr={EJOR},
preview={homepage_reusable.png},
bibtex_show={true},
title = {Reinforcement Learning Algorithm for Reusable Resource Allocation with Unknown Rental Time Distribution},
journal = {European Journal of Operational Research},
year = {2025},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2025.09.012},
url = {https://www.sciencedirect.com/science/article/pii/S0377221725007295},
author = {Ziwei Wang and Jie Song and Yixuan Liu and Jingtong Zhao},
pdf = {reusable_ssrn.pdf},
selected = {true},
keywords = {Reusable resources, Online resource allocation, Episodic reinforcement learning, Markov decision process},
abstract = {We explore a scenario where a platform must decide on the price and type of reusable resources for sequentially arriving customers. The product is rented for a random period, during which the platform also extracts rewards based on a prearranged agreement. The expected reward varies during the usage time, and the platform aims to maximize revenue over a finite horizon. Two primary challenges are encountered: the stochastic usage time introduces uncertainty, affecting product availability, and the platform lacks initial knowledge about reward and usage time distributions. In contrast to conventional online learning, where usage time distributions are parametric, our problem allows for unknown distribution types. To overcome these challenges, we formulate the problem as a Markov decision process and model the usage time distribution using a hazard rate. We first introduce a greedy policy in the full-information setting with a provable 1/2-approximation ratio. We then develop a reinforcement learning algorithm to implement this policy when the parameters are unknown, allowing for non-parametric distributions and time-varying rewards. We further prove that the algorithm achieves sublinear regret against the greedy policy. Numerical experiments on synthetic data as well as a real dataset from TikTok demonstrate the effectiveness of our method.}
}

@INPROCEEDINGS{Gao2024,
  abbr = {YAC},
  preview = {homepage_Lyapunov_slower.gif},
  bibtex_show={true},
  author={Kekun Gao and Yuejun Yan and Yixuan Liu and Endong Liu and Pengcheng You},
  booktitle={2024 39th Youth Academic Annual Conference of Chinese Association of Automation (YAC)}, 
  title={Online Electricity Purchase for Data Center with Dynamic Virtual Battery from Flexibility Aggregation}, 
  year={2024},
  volume={},
  number={},
  pages={2170-2175},
  keywords={Procurement;Data centers;Renewable energy sources;Costs;Uncertainty;Electricity;Heuristic algorithms},
  pdf = {homepage_Lyapunov.pdf},
  selected = {true},
  doi={10.1109/YAC63405.2024.10598509},
  abstract = {As a critical component of modern infrastructure, data centers account for a huge amount of power consumption and greenhouse gas emission. This paper studies the electricity purchase strategy for a data center to lower its energy cost while integrating local renewable generation under uncertainty. To facilitate efficient and scalable decision-making, we propose a two-layer hierarchy where the lower layer consists of the operation of all electrical equipment in the data center and the upper layer determines the procurement and dispatch of electricity. At the lower layer, instead of device-level scheduling in real time, we propose to exploit the inherent flexibility in demand, such as thermostatically controlled loads and flexible computing tasks, and aggregate them into virtual batteries. By this means, the upper-layer decision only needs to take into account these virtual batteries, the size of which is generally small and independent of the data center scale. We further propose an online algorithm based on Lyapunov optimization to purchase electricity from the grid with a manageable energy cost, even though the prices, renewable availability, and battery specifications are uncertain and dynamic. In particular, we show that, under mild conditions, our algorithm can achieve bounded loss compared with the offline optimal cost, while strictly respecting battery operational constraints. Extensive simulation studies validate the theoretical analysis and illustrate the tradeoff between optimality and conservativeness.}
  }

